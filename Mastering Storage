========================
# Part 1: Understanding the exsiting pod's stroage

kubectl run nginx-cli1 --image=beyondcloudai/nginx:v1 --port=80 --restart=Never
kubectl get pods nginx-cli -o=jsonpath='{.metadata.uid}'


========================
# Part 2: Understanding the exsiting pod's stroage

kubectl run nginx-cli --image=beyondcloudai/nginx:v1 --port=80 --restart=Never


========================
# Part 3: Understanding EmptyDir Storage

vi storage-pod1.yaml

apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
spec:
  containers:
  - name: nginx-container
    image: nginx
    volumeMounts:
    - name: html
      mountPath: /usr/share/nginx/html
  volumes:
  - name: html
    emptyDir: {}
:wq


========================
# Part 4: Understanding HostPath (bind) Storage

[root@manager1 pods]# mkdir -p /opt/software/content/html/
[root@manager1 pods]# cat > /opt/software/content/html/index.html
this is pod2 example
^D <To Quit Cat>

vi storage-pod2.yaml

apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: mycontainer
    image: nginx
    volumeMounts:
    - name: host-volume
      mountPath: /usr/share/nginx/html/  # Mount point inside the container
  volumes:
  - name: host-volume
    hostPath:
      path: /opt/software/content/html/  # Path on the host node's filesystem
:wq


========================
# Part 5: Advanced EmptyDir Storage

vi storage-pod3.yaml

apiVersion: v1
kind: Pod
metadata:
  name: volume-sharing-pod
spec:
  containers:
  - name: nginx-container
    image: nginx
    volumeMounts:
    - name: shared-volume
      mountPath: /nginx-data
  - name: os-container
    image: alpine
    command: ["sleep", "3600"]
    volumeMounts:
    - name: shared-volume
      mountPath: /os-data
  volumes:
  - name: shared-volume
    emptyDir: {}
:wq


========================
# Part 6: Basic RW and RO Storage

vi stroage-pod4.yaml

apiVersion: v1
kind: Pod
metadata:
  name: volume-sharing-pod
spec:
  containers:
  - name: nginx-container
    image: nginx
    volumeMounts:
    - name: shared-volume
      mountPath: /nginx-data
      readOnly: true  # Set to true for read-only access
  - name: os-container
    image: alpine
    command: ["sleep", "3600"]
    volumeMounts:
    - name: shared-volume
      mountPath: /os-data
  volumes:
  - name: shared-volume
    emptyDir: {}
:wq


========================
# Part 7: Advanced RW and RO Storage

vi stroage-pod5.yaml

apiVersion: v1
kind: Pod
metadata:
  name: volume-sharing-pod
spec:
  containers:
  - name: os-container
    image: alpine
    command: ["/bin/sh"]
    args: ["-c","while true;do date >> /var/html/index.html; hostname >> /var/html/index.html; sleep 10;done"]
    volumeMounts:
    - name: shared-volume
      mountPath: /var/html/
  - name: nginx-container
    image: nginx
    volumeMounts:
    - name: shared-volume
      mountPath: /usr/share/nginx/html
      readOnly: true  # Set to true for read-only access
  volumes:
  - name: shared-volume
    emptyDir: {}
:wq


========================
# Part 7: NFS Installation

# install this on all the nodes
yum -y install nfs-utils 

#only on the nfs server
vi /etc/exports
/mnt/nfs/ 10.0.15.0/24(rw,sync,root_squash,no_subtree_check) 172.24.0.0/24(rw,sync,root_squash,no_subtree_check) 172.18.0.0/24(rw,sync,root_squash,no_subtree_check) 172.17.0.0/24(rw,sync,root_squash,no_subtree_check) 10.244.1.0/24(rw,sync,root_squash,no_subtree_check)
:wq

systemctl start nfs-server.service
exportfs -av

#Check if its working with the below command on another node
mount -t nfs manager1:/mnt/nfs /mnt/ -vvv
chmod 777 /mnt/nfs -R # why this needs needs to be enabled or run is covered on the nfs with jenkins session.

========================
# Part 8: Basic NFS Storage

vi stroage-pod6.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nfs-pod
spec:
  containers:
  - name: nginx-container
    image: nginx
    volumeMounts:
    - name: nfs-volume
      mountPath: /usr/share/nginx/html
  volumes:
  - name: nfs-volume
    nfs:
      server: nfs-server.example.com   # Replace with your NFS server address
      path: /path/to/your/nfs/share    # Replace with the NFS share path
:wq

========================
# Part 9: Advanced NFS Storage with Jenkins

vi stroage-pod7.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jenkins-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jenkins
  template:
    metadata:
      labels:
        app: jenkins
    spec:
      containers:
      - name: jenkins
        image: jenkins/jenkins:latest
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 50000
          name: jnlp
        volumeMounts:
        - name: jenkins-home
          mountPath: /var/jenkins_home
      volumes:
      - name: jenkins-home
        nfs:
          server: nfs-server.example.com
          path: /path/to/your/nfs/share

---
apiVersion: v1
kind: Service
metadata:
  name: jenkins-service
spec:
  type: NodePort
  selector:
    app: jenkins
  ports:
  - port: 8080
    targetPort: 8080
    nodePort: 30000  # Adjust the nodePort as needed
    protocol: TCP
:wq


========================
# Part 10: Persistant Volumes

Step 1:
vi storage-pv1.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-pv
  labels:
    name: my-pv
    type: local
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: manual
  hostPath:
    path: "/mnt/pv"
:wq


Step 2:
vi storage-pvc1.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: manual
  selector:
    matchLabels:
      name: my-pv
:wq


Step 3:

vi storage-pod8.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app-container
          image: nginx
          volumeMounts:
            - name: my-volume
              mountPath: /usr/share/nginx/html
      volumes:
        - name: my-volume
          persistentVolumeClaim:
            claimName: my-pvc
:wq


========================
# Part 11: Persistant Volumes with NFS

Step 1:
vi storage-pv2.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: manual
  nfs:
    path: /path/to/nfs/share
    server: nfs-server-ip
:wq

vi storage-pvc2.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi
  storageClassName: manual
:wq

vi storage-pod9.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nfs-app
  template:
    metadata:
      labels:
        app: nfs-app
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        volumeMounts:
        - name: nfs-volume
          mountPath: /usr/share/nginx/html
      volumes:
      - name: nfs-volume
        persistentVolumeClaim:
          claimName: nfs-pvc
:wq

========================
# Part 12: Troubleing PV, PVC & Access Modes

Step 1:
vi storage-pv3.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: manual
  nfs:
    path: /mnt/nfs
    server: manager1.kube.com
:wq

Step 2: 

vi storage-pvc3.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: manual
:wq

Step 3:

vi storage-pod10.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nfs-app
  template:
    metadata:
      labels:
        app: nfs-app
    spec:
      containers:
      - name: os-container
        image: alpine
        command: ["/bin/sh"]
        args: ["-c","while true;do date >> /var/html/index.html; hostname >> /var/html/index.html; sleep 10;done"]
        volumeMounts:
        - name: nfs-volume
          mountPath: /var/html/
        readinessProbe:
          exec:
            command: ["test","-e","/var/html/index.html"]
          initialDelaySeconds: 5
          timeoutSeconds: 10
          periodSeconds: 5
          successThreshold: 1
          failureThreshold: 3
      - name: nginx
        image: nginx:latest
        volumeMounts:
        - name: nfs-volume
          mountPath: /usr/share/nginx/html
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 3
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 3
      volumes:
      - name: nfs-volume
        persistentVolumeClaim:
          claimName: nfs-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: NodePort
  selector:
    app: nfs-app
  ports:
  - port: 80
    targetPort: 80
    nodePort: 30000  # Adjust the nodePort as needed
    protocol: TCP

:wq

========================
# Part 13: Dynamic PersistantVolume

step 1: 

vi rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: default
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: default
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: default
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: default
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: default
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io
:wq


Step 2:

vi storage-pr1.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  labels:
    app: nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: default
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      nodeSelector:                    # Specify node selector here
        kubernetes.io/hostname: manager1
      serviceAccountName: nfs-client-provisioner
      containers:
        - name: nfs-client-provisioner
          image: gcr.io/k8s-staging-sig-storage/nfs-subdir-external-provisioner:v4.0.1
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: k8s-sigs.io/nfs-subdir-external-provisioner
            - name: NFS_SERVER
              value: manager1.kube.com
            - name: NFS_PATH
              value: /mnt/nfs
      volumes:
        - name: nfs-client-root
          nfs:
            server: manager1.kube.com
            path: /mnt/nfs
:wq

Step 3:

vi storage-class1.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-storage-class
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner
allowVolumeExpansion: true
reclaimPolicy: Retain
:wq

Step 4: 

vi storage-pvc4.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: nfs-storage-class
  resources:
    requests:
      storage: 5Gi
:wq

Step 5:

vi storage-pod11.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nfs-app
  template:
    metadata:
      labels:
        app: nfs-app
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        volumeMounts:
        - name: nfs-volume
          mountPath: /usr/share/nginx/html
      volumes:
      - name: nfs-volume
        persistentVolumeClaim:
          claimName: nfs-pvc
:wq


========================
Part 14: Advanced Dynamic PersistantVolume

Step 1:

vi storage-class2.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: web-storage-class
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner
allowVolumeExpansion: true
reclaimPolicy: Delete
parameters:
  archiveOnDelete: "true"
:wq


vi storage-class3.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: app-storage-class
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner
allowVolumeExpansion: true
reclaimPolicy: Retain
:wq


vi storage-pvc6.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: web-pvc
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: web-storage-class
  resources:
    requests:
      storage: 5Mi
:wq


vi storage-pvc7.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: app-pvc
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: app-storage-class
  resources:
    requests:
      storage: 100Mi
:wq


vi storage-pod12.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sterling-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: sterling-app
  template:
    metadata:
      labels:
        app: sterling-app
        env: production
        type: deployment
        version: v1
    spec:
      containers:
      - name: os-container
        image: alpine
        command: ["/bin/sh"]
        args: ["-c","while true;do date >> /var/html/index.html; hostname >> /var/html/index.html; sleep 10;done"]
        volumeMounts:
        - name: web-volume
          mountPath: /var/html/
        readinessProbe:
          exec:
            command: ["test","-e","/var/html/index.html"]
          initialDelaySeconds: 5
          timeoutSeconds: 10
          periodSeconds: 5
          successThreshold: 1
          failureThreshold: 3
      - name: nginx
        image: nginx:latest
        volumeMounts:
        - name: web-volume
          mountPath: /usr/share/nginx/html
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 3
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 3
      - name: tomcat
        image: tomcat:latest
        volumeMounts:
        - name: app-volume
          mountPath: /usr/local/tomcat/webapps
      volumes:
      - name: web-volume
        persistentVolumeClaim:
          claimName: web-pvc
      - name: app-volume
        persistentVolumeClaim:
          claimName: app-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: NodePort
  selector:
    app: sterling-app
  ports:
  - port: 80
    targetPort: 80
    nodePort: 30000  # Adjust the nodePort as needed
    protocol: TCP

:wq


